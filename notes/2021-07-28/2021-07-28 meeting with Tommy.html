<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<p>Two linear transforms can be composed into 1.</p>
<p>Three reasons for loss fluctuation around the same value: 1) Model is too small for the dataset and can't fit any signal. 2) Learning rate is too small or too high. 3) Data is corrupted or labels don't match the features. 4) Dataset is unlearnable (too hard - think trying to fit noise).</p>
<p>Add a command-line-argument that controls whether or not our model overfits on a subset of data (or just have a variable in your code).</p>
<p>We have a new distribution of classes in our dataset: Test and train shown in the *pngs in this directory.</p>
<p>We're seeing bad accuracy on the test set despite the fact that the model is converging on the train set (90+%).</p>
<p>Did we prepare the train and test data in the same way (i.e. one has a log transform and the other doesn't). Are the number of examples per class extremely different between the test and the train set?</p>
<p>open_and_look at the test and the train examples side by side and with colorbars.</p>
<p>Does the performance differ if we go back to mel spectrograms + log transform?</p>
<p>we know that a 2d cnn can do well on the mel spects + log transform. Let's try a 1-d cnn with the original data!</p>
<ul>
<li>Keep a record of all of the data in an organized fashion*</li>
</ul>
<p>data ├── test</p>
<p><code>   ├── mel_log</code><br />
<code>   ├── mel_no_log</code><br />
<code>   └── raw_spect</code></p>
<p>├── train │   ├── mel_log │   ├── mel_no_log │   └── raw_spect └── valid</p>
<p><code>   ├── mel_log</code><br />
<code>   ├── mel_no_log</code><br />
<code>   └── raw_spect</code><br />
<code>   </code></p>
<p>Concrete TODO:</p>
<p><code>- Go back to the original problem (2d CNN, original spect preprocessing), and</code><br />
<code>  fit the data with a 1d CNN. If this works,</code><br />
<code>- Turn off Mel. If this works,</code><br />
<code>- Turn off log2.</code><br />
<code>- IF the first one doesn't work: We need to examine the quality of the labels</code><br />
<code>  and the distribution of classes in test and train.</code></p>
</body>
</html>
